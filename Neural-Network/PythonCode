#install.packages("data.table")
#install.packages("pracma")

library(data.table) # allows us to use function fread,
# which quickly reads data from csv files 

accuracy <- function(p, y) 
{
  return(mean((p > 0.5) == (y == 1)))
}



train <- function(X, Y, Xtest, Ytest, m=100, num_iterations=2000,
          learning_rate=1e-1) 
{
  n = dim(X)[1] 
  p = dim(X)[2]+1
  ntest = dim(Xtest)[1]

  X1 = cbind(rep(1, n), X)
  Xtest1 = cbind(rep(1, ntest), Xtest)
    
  sigma = .1; 
  alpha = matrix(rnorm(p*m)*sigma, nrow=p)
  beta = matrix(rnorm(m+1)*sigma, nrow=m+1)
  accuracies_train=NULL
  accuracies_test=NULL
for(it in 1:num_iterations)
{
  z=1/(1+exp(-(X1%*%alpha)))
  z1=cbind(rep(1,n),z)
  pr=1/(1+exp(-(z1%*%beta)))
  
  s=1/(1+exp(-(Xtest1%*%alpha)))
  s1=cbind(rep(1,ntest),s)
  prs=1/(1+exp(-(s1%*%beta)))
  
  dbeta=matrix(rep(1,n),nrow=1)%*%(matrix(Y-pr,n,m+1)*z1)/n
  beta=beta+learning_rate*t(dbeta)
  
  
  accuracies_train = append(accuracies_train,accuracy(pr, Y))
  accuracies_test = append(accuracies_test,accuracy(prs, Ytest))
  if (it %% 100 == 0){
    print(c(it,accuracies_train[length(accuracies_train)], accuracies_test[length(accuracies_test)]))
  }
  for(k in 1:m)
  {
    da=(Y-pr)*beta[k+1]*z[,k]*(1-z[,k])
    dalpha=matrix(rep(1,n),nrow=1)%*%(matrix(da,n,p)*X1)/n
    alpha[,k]=alpha[,k]+learning_rate*t(dalpha)
  }
}
#return(beta)


    
model = list(beta,alpha)
return(list(model, accuracies_train, accuracies_test))
}



# load data
load_digits <- function(subset=NULL, normalize=TRUE) {
  
#Load digits and labels from digits.csv.

#Args:
#subset: A subset of digit from 0 to 9 to return.
#If not specified, all digits will be returned.
#normalize: Whether to normalize data values to between 0 and 1.

#Returns:
#digits: Digits data matrix of the subset specified.
#The shape is (n, p), where
#n is the number of examples,
#p is the dimension of features.
#labels: Labels of the digits in an (n, ) array.
#Each of label[i] is the label for data[i, :]

# load digits.csv, adopted from sklearn.

df <- fread("digits.csv") 
df <- as.matrix(df)

## only keep the numbers we want.
if (length(subset)>0) {
  
  c <- dim(df)[2]
  l_col <- df[,c]
  index = NULL
  
  for (i in 1:length(subset)){
    
    number = subset[i]
    index = c(index,which(l_col == number))
  }
  sort(index)
  df = df[index,]
}

# convert to arrays.
digits = df[,-1]
labels = df[,c]

# Normalize digit values to 0 and 1.
if (normalize == TRUE) {
  digits = digits - min(digits)
digits = digits/max(digits)}


# Change the labels to 0 and 1.
for (i in 1:length(subset)) {
  labels[labels == subset[i]] = i-1
}

return(list(digits, labels))

}

split_samples <- function(digits,labels) {

# Split the data into a training set (70%) and a testing set (30%).

num_samples <- dim(digits)[1]
num_training <- round(num_samples*0.7)
indices = sample(1:num_samples, size = num_samples)
training_idx <- indices[1:num_training]
testing_idx <- indices[-(1:num_training)]

return (list(digits[training_idx,], labels[training_idx],
        digits[testing_idx,], labels[testing_idx]))
}


#====================================
# Load digits and labels.
result = load_digits(subset=c(3, 5), normalize=TRUE)
digits = result[[1]]
labels = result[[2]]

result = split_samples(digits,labels)
training_digits = result[[1]]
training_labels = result[[2]]
testing_digits = result[[3]]
testing_labels = result[[4]]

# print dimensions
length(training_digits)
length(testing_digits)

# Train a net and display training accuracy.
result=train(training_digits, training_labels, testing_digits, testing_labels)
plot(1:length(result[[2]]),result[[2]],xlab='Iteration',ylab='Accuracy_train')
plot(1:length(result[[3]]),result[[3]],xlab='Iteration',ylab='Accuracy_test')

