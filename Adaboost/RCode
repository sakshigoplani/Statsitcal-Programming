library(data.table) # allows us to use function fread,
# which quickly reads data from csv files

digits <- read.csv("digits.csv")

accuracy <- function(S, y) 
{
  return(mean(sign(S)*y))
}


train <- function(X, Y, Xtest, Ytest, m=100, num_iterations=4000)
                   
{
  n = dim(X)[1] 
  p = dim(X)[2]
  ntest = dim(Xtest)[1]
  th=0.5
  X1 = X>th
  X1 = 2*X1-1
  
  Xtest1=Xtest>th
  Xtest1=2*Xtest1-1
  #print(dim(X1))
  Y = Y*2-1
  Ytest=Ytest*2-1
  #Xtest1 = cbind(rep(1, ntest), Xtest)
  beta=matrix(rep(0,p),nrow=p)
  #print(dim(beta))
 
  accuraciestrain = NULL
  accuraciestest = NULL
  
  for(it in 1:num_iterations)
  {
    S=X1%*%beta
    w=exp(-Y*S)
    y_train=sign(S)
    
    Stest=Xtest1%*%beta
    wtest=exp(-Ytest*Stest)
    y_test=sign(Stest)
    
    a=matrix(rep(1,n),nrow=1)%*%(matrix(w*Y,n,p)*X1)/n
    e=(1-a)/2
    j=which.min(e)
    #print(dim(j))
    beta[j]=beta[j]+log((1-e[j])/e[j])/2
    
    #print(beta)
    
    #y_train = 1/(1+exp(-X1%*%beta)) 
    accuraciestrain = append(accuraciestrain,accuracy(y_train, Y))
    
    
    #y_test = 1/(1+exp(-Xtest%*%beta)) 
    accuraciestest = append(accuraciestest,accuracy(y_test, Ytest))
    
    if (it %% 100 == 0){
      print(c(it,accuraciestrain[length(accuraciestrain)],accuraciestest[length(accuraciestest)]))
    }
  }
  
  return(list(beta, accuraciestrain, accuraciestest))
  
}


# load data
load_digits <- function(subset=NULL, normalize=TRUE) {
  
  #Load digits and labels from digits.csv.
  
  #Args:
  #subset: A subset of digit from 0 to 9 to return.
  #If not specified, all digits will be returned.
  #normalize: Whether to normalize data values to between 0 and 1.
  
  #Returns:
  #digits: Digits data matrix of the subset specified.
  #The shape is (n, p), where
  #n is the number of examples,
  #p is the dimension of features.
  #labels: Labels of the digits in an (n, ) array.
  #Each of label[i] is the label for data[i, :]
  
  # load digits.csv, adopted from sklearn.
  
  df <- fread("digits.csv") 
  df <- as.matrix(df)
  
  ## only keep the numbers we want.
  if (length(subset)>0) {
    
    c <- dim(df)[2]
    l_col <- df[,c]
    index = NULL
    
    for (i in 1:length(subset)){
      
      number = subset[i]
      index = c(index,which(l_col == number))
    }
    sort(index)
    df = df[index,]
  }
  
  # convert to arrays.
  digits = df[,-1]
  labels = df[,c]
  
  # Normalize digit values to 0 and 1.
  if (normalize == TRUE) {
    digits = digits - min(digits)
    digits = digits/max(digits)}
  
  
  # Change the labels to 0 and 1.
  for (i in 1:length(subset)) {
    labels[labels == subset[i]] = i-1
  }
  
  return(list(digits, labels))
  
}

split_samples <- function(digits,labels) {
  
  # Split the data into a training set (70%) and a testing set (30%).
  
  num_samples <- dim(digits)[1]
  num_training <- round(num_samples*0.7)
  indices = sample(1:num_samples, size = num_samples)
  training_idx <- indices[1:num_training]
  testing_idx <- indices[-(1:num_training)]
  
  return (list(digits[training_idx,], labels[training_idx],
               digits[testing_idx,], labels[testing_idx]))
}


#====================================
# Load digits and labels.
result = load_digits(subset=c(1, 7), normalize=TRUE)
digits = result[[1]]
labels = result[[2]]

result = split_samples(digits,labels)
training_digits = result[[1]]
training_labels = result[[2]]
testing_digits = result[[3]]
testing_labels = result[[4]]

# print dimensions
length(training_digits)
length(testing_digits)

# Train a net and display training accuracy.
result = train(training_digits, training_labels, testing_digits, testing_labels)
par(mfrow=c(1,2))
plot(1:length(result[[2]]),result[[2]],xlab='Iteration',ylab='Accuracy_train')
plot(1:length(result[[3]]),result[[3]],xlab='Iteration',ylab='Accuracy_test')

